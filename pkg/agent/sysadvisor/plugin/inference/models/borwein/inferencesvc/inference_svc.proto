/*
Copyright 2022 The Katalyst Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

syntax = 'proto3';

package inferencesvc;

import "github.com/gogo/protobuf/gogoproto/gogo.proto";

option (gogoproto.goproto_stringer_all) = false;
option (gogoproto.stringer_all) =  true;
option (gogoproto.goproto_getters_all) = true;
option (gogoproto.marshaler_all) = true;
option (gogoproto.sizer_all) = true;
option (gogoproto.unmarshaler_all) = true;
option (gogoproto.goproto_unrecognized_all) = false;

option go_package = "github.com/kubewharf/katalyst-core/pkg/agent/sysadvisor/plugin/inference/models/bowein/inferencesvc";

message InferenceRequest {
    repeated string feature_names = 1;
    map<string,ContainerRequestEntries> pod_request_entries = 2; // keyed by podUID
}

message ContainerRequestEntries {
    map<string,FeatureValues> container_feature_values = 1; // keyed by container name
}

message FeatureValues {
    repeated string values = 1;
}

message InferenceResponse {
    map<string,ContainerResponseEntries> pod_response_entries = 1; // keyed by podUID
}

message ContainerResponseEntries {
    map<string,InferenceResults> container_inference_results = 1; // keyed by container name
}

message InferenceResults {
    repeated InferenceResult inference_results = 1; // different kinds of inference results
}

enum InferenceType {
    ClassificationOverload = 0;
    ClassificationUnderload = 1;
    LatencyRegression = 2;
    Other = 15;
}

message InferenceResult {
    // if use default model. default model should be trained using all service data for fallback.
    bool is_default  = 1;
    InferenceType inference_type = 2;
    // Inference output, values are varied by inference target.
    // For classification, the output would be range from 0 to 1.
    // For regression, the output would be the predicted value.
    // It depends on the inference target.
    float output = 3;
    // threshold to judge overload or underload. should be float between 0 and 1.
    float percentile = 4;
    // model_version to identify where does the output come from.
    string model_version = 5;
    // generic_output provides specific inference result from corresponding model,
    // it will be decoded by the specific client accesses the model.
    string generic_output = 6;
}

service InferenceService {
    rpc Inference(InferenceRequest) returns (InferenceResponse) {}
}
